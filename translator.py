#!/usr/bin/env python3
"""
Streamlit ê¸°ë°˜ì˜ ëŒ€í™”í˜• ë¬¸ì„œ ë²ˆì—­ê¸°
"""
import json
import os
import re
from pathlib import Path
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

# --- Core Logic Functions ---

@st.cache_data
def load_prompt_template(prompt_path: str) -> str:
    """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë¡œë“œí•˜ê³  ìºì‹œí•©ë‹ˆë‹¤."""
    with open(prompt_path, 'r', encoding='utf-8') as f:
        return f.read()

@st.cache_data
def load_glossary(_glossary_path: str) -> list:
    """ë‹¨ì–´ì‚¬ì „ íŒŒì¼ì„ ë¡œë“œí•˜ê³  ìºì‹œí•©ë‹ˆë‹¤."""
    with open(_glossary_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def get_glossary_terms(glossary_data: list) -> tuple[list, list]:
    """ë‹¨ì–´ì‚¬ì „ì—ì„œ ì›ë¬¸/ë²ˆì—­ë¬¸ ìš©ì–´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    source_terms = [entry["source"] for entry in glossary_data]
    target_terms = []
    for entry in glossary_data:
        target = entry["target"]  # í•­ìƒ ë¦¬ìŠ¤íŠ¸
        target_terms.extend(target)
    return source_terms, target_terms

def highlight_terms(text: str, terms: list) -> str:
    """ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ ìš©ì–´ë“¤ì„ ì°¾ì•„ ë³¼ë“œ ì²˜ë¦¬í•˜ê³  íŒŒë€ìƒ‰ìœ¼ë¡œ ê°•ì¡°í•˜ë˜, ì½”ë“œ ë¸”ë¡ê³¼ ì¸ë¼ì¸ ì½”ë“œëŠ” ì œì™¸í•©ë‹ˆë‹¤."""
    if not terms:
        return text

    # ê¸´ ìš©ì–´ë¥¼ ë¨¼ì € ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    sorted_terms = sorted(terms, key=len, reverse=True)
    
    # ì½”ë“œ ë¸”ë¡, ì¸ë¼ì¸ ì½”ë“œ, ë˜ëŠ” ê°•ì¡°í•  ìš©ì–´ë¥¼ ì°¾ëŠ” ì •ê·œì‹
    # 1. ì½”ë“œ ë¸”ë¡ (```...```)
    # 2. ì¸ë¼ì¸ ì½”ë“œ (`...`)
    # 3. ê°•ì¡°í•  ìš©ì–´ë“¤
    term_pattern = '|'.join(re.escape(term) for term in sorted_terms)
    pattern = re.compile(
        rf"(```.*?```|`.*?`|{term_pattern})", 
        re.DOTALL | re.IGNORECASE
    )

    def replace_match(match):
        matched_text = match.group(0)
        # ì½”ë“œ ë¸”ë¡ì´ë‚˜ ì¸ë¼ì¸ ì½”ë“œì¸ ê²½ìš°, ê·¸ëŒ€ë¡œ ë°˜í™˜
        if matched_text.startswith('`'):
            return matched_text
        # ìš©ì–´ì¸ ê²½ìš°, ë³¼ë“œ ì²˜ë¦¬í•˜ê³  íŒŒë€ìƒ‰ìœ¼ë¡œ ê°•ì¡°í•˜ì—¬ ë°˜í™˜
        return f'<span style="color: blue; font-weight: bold;">{matched_text}</span>'

    return pattern.sub(replace_match, text)

def prepare_final_prompt(base_prompt: str, glossary_data: list) -> str:
    """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ë‹¨ì–´ì‚¬ì „ ê·œì¹™ì„ ê²°í•©í•©ë‹ˆë‹¤."""
    instructions = []
    for entry in glossary_data:
        source = entry["source"]
        target = entry["target"]  # í•­ìƒ ë¦¬ìŠ¤íŠ¸
        target_str = json.dumps(target, ensure_ascii=False)
        instructions.append(f'- "{source}" â†’ {target_str}')
    glossary_instructions = "\n".join(instructions)
    return base_prompt.replace("{glossary_instructions}", glossary_instructions)

def split_markdown_by_headings(markdown_content: str) -> list[str]:
    """ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸ ë¥¼ ì œëª©(#) ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•˜ë˜, ì½”ë“œ ë¸”ë¡ ë‚´ì˜ ì£¼ì„ì€ ì œì™¸í•©ë‹ˆë‹¤."""
    chunks = []
    current_chunk_lines = []
    in_code_block = False
    for line in markdown_content.splitlines():
        if line.strip().startswith('```'):
            in_code_block = not in_code_block
        
        if line.startswith('#') and not in_code_block:
            if current_chunk_lines:
                chunks.append("\n".join(current_chunk_lines))
            current_chunk_lines = [line]
        else:
            current_chunk_lines.append(line)
    if current_chunk_lines:
        chunks.append("\n".join(current_chunk_lines))
    return chunks

# --- Streamlit UI ---

st.set_page_config(layout="wide", page_title="AI ë¬¸ì„œ ë²ˆì—­ê¸°")
st.title("ğŸ¤— AI ë¬¸ì„œ ë²ˆì—­ê¸°")

# --- Initialize session state ---
if "translation_done" not in st.session_state:
    st.session_state.translation_done = False
if "source_chunks" not in st.session_state:
    st.session_state.source_chunks = []
if "show_progress_view" not in st.session_state:
    st.session_state.show_progress_view = False

# --- Sidebar for Settings ---
with st.sidebar:
    st.header("âš™ï¸ ë²ˆì—­ ì„¤ì •")
    
    # .env íŒŒì¼ ë¡œë“œ
    load_dotenv()
    
    api_key = st.text_input(
        "OpenAI API Key", 
        value=os.getenv("OPENAI_API_KEY", ""), 
        type="password",
        help="API í‚¤ê°€ ì—†ìœ¼ë©´ https://platform.openai.com/api-keys ì—ì„œ ë°œê¸‰ë°›ìœ¼ì„¸ìš”."
    )
    
    model_name = st.text_input("ëª¨ë¸ ì´ë¦„", value="gpt-4o")
    
    st.subheader("íŒŒì¼ ê²½ë¡œ")
    source_path = st.text_input("ì›ë³¸ ë¬¸ì„œ", value="./source_docs/models.md")
    prompt_path = st.text_input("í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿", value="./prompts/nmt.yaml")
    glossary_path = st.text_input("ë‹¨ì–´ì‚¬ì „", value="./glossary/glossary.json")
    output_path = st.text_input("ë²ˆì—­ ê²°ê³¼ ì €ì¥ ê²½ë¡œ", value="./output/models_ko.md")

    if st.button("ë²ˆì—­ ì‹œì‘", type="primary"):
        st.session_state.show_progress_view = True
        st.session_state.translation_done = False
        st.rerun()

# --- Main App Logic ---
if st.session_state.show_progress_view:
    st.session_state.show_progress_view = False  # í•œë²ˆë§Œ ì‹¤í–‰ë˜ë„ë¡ ì¬ì„¤ì •

    if not api_key:
        st.error("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not all([source_path, prompt_path, glossary_path, output_path]):
        st.error("ëª¨ë“  íŒŒì¼ ê²½ë¡œë¥¼ ì˜¬ë°”ë¥´ê²Œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        try:
            # 1. ì´ˆê¸°í™”
            llm = ChatOpenAI(model=model_name, temperature=0.1, openai_api_key=api_key)
            base_prompt = load_prompt_template(prompt_path)
            glossary_data = load_glossary(glossary_path)
            final_prompt_template = prepare_final_prompt(base_prompt, glossary_data)
            source_terms, target_terms = get_glossary_terms(glossary_data)

            # 2. ì›ë³¸ ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• 
            with open(source_path, 'r', encoding='utf-8') as f:
                source_content = f.read()
            
            source_chunks = split_markdown_by_headings(source_content)
            st.session_state.source_chunks = source_chunks
            
            st.info(f"âœ… ì´ {len(source_chunks)}ê°œì˜ ë¬¸ë‹¨ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

            # 3. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë²ˆì—­ ë° ê²°ê³¼ í‘œì‹œ
            for i, chunk in enumerate(source_chunks):
                st.subheader(f"ë¬¸ë‹¨ {i+1}/{len(source_chunks)}")
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("### ì›ë³¸")
                    highlighted_source = highlight_terms(chunk, source_terms)
                    with st.container(border=True):
                        st.markdown(highlighted_source, unsafe_allow_html=True)

                with col2:
                    st.markdown("### ë²ˆì—­ ê²°ê³¼")
                    with st.container(border=True):
                        if not chunk.strip():
                            final_chunk = chunk
                            st.markdown(final_chunk)
                        else:
                            prompt = final_prompt_template.replace("{source}", chunk)
                            
                            placeholder = st.empty()
                            final_chunk = ""
                            try:
                                for response in llm.stream(prompt):
                                    content = response.content
                                    if content:
                                        final_chunk += content
                                        placeholder.markdown(final_chunk + "â–Œ") # ì‹¤ì‹œê°„ ì»¤ì„œ íš¨ê³¼
                                
                                # í›„ì²˜ë¦¬: í•œ ì¤„ì§œë¦¬ ì½”ë“œ ë¸”ë¡ì„ ì¸ë¼ì¸ ì½”ë“œë¡œ ë³€ê²½
                                stripped_chunk = final_chunk.strip()
                                lines = stripped_chunk.splitlines()
                                if (
                                    stripped_chunk.startswith('```') and
                                    stripped_chunk.endswith('```') and
                                    lines[0].strip() == '```' and
                                    '\n' not in stripped_chunk[3:-3].strip()
                                ):
                                    inner_content = stripped_chunk[3:-3].strip()
                                    final_chunk = f"`{inner_content}`"
                                
                                # ìµœì¢… ê²°ê³¼ì— ìš©ì–´ ê°•ì¡° ì ìš©í•˜ì—¬ í‘œì‹œ
                                highlighted_final = highlight_terms(final_chunk, target_terms)
                                placeholder.markdown(highlighted_final, unsafe_allow_html=True)
                            except Exception as e:
                                st.error(f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                                final_chunk = f"ì˜¤ë¥˜: {e}"

                        # í›„ì²˜ë¦¬: í•œ ì¤„ì§œë¦¬ ì½”ë“œ ë¸”ë¡ì„ ì¸ë¼ì¸ ì½”ë“œë¡œ ë³€ê²½
                        stripped_chunk = final_chunk.strip()
                        lines = stripped_chunk.splitlines()
                        if (
                            stripped_chunk.startswith('```') and
                            stripped_chunk.endswith('```') and
                            lines[0].strip() == '```' and
                            '\n' not in stripped_chunk[3:-3].strip()
                        ):
                            inner_content = stripped_chunk[3:-3].strip()
                            final_chunk = f"`{inner_content}`"

                        st.session_state[f"edited_chunk_{i}"] = final_chunk

            st.session_state.translation_done = True
            st.success("ğŸ‰ ë²ˆì—­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì ì‹œ í›„ í¸ì§‘ ëª¨ë“œë¡œ ì „í™˜ë©ë‹ˆë‹¤.")
            import time
            time.sleep(2)
            st.rerun()

        except FileNotFoundError as e:
            st.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e.filename}")
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# --- Display, Edit, and Save UI ---
if st.session_state.translation_done:
    try:
        source_chunks = st.session_state.source_chunks
        glossary_data = load_glossary(glossary_path)
        source_terms, target_terms = get_glossary_terms(glossary_data)

        # ê° ì²­í¬ì˜ í¸ì§‘ ìƒíƒœ ì´ˆê¸°í™”
        for i in range(len(source_chunks)):
            if f"editing_chunk_{i}" not in st.session_state:
                st.session_state[f"editing_chunk_{i}"] = False

        for i, chunk in enumerate(source_chunks):
            st.subheader(f"ë¬¸ë‹¨ {i+1}/{len(source_chunks)}")
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### ì›ë³¸")
                highlighted_source = highlight_terms(chunk, source_terms)
                with st.container(border=True):
                    st.markdown(highlighted_source, unsafe_allow_html=True)
            
            with col2:
                is_editing = st.session_state.get(f"editing_chunk_{i}", False)
                
                title_col, button_col = st.columns([0.8, 0.2])

                with title_col:
                    st.markdown("### ë²ˆì—­ ê²°ê³¼")

                if is_editing:
                    # í¸ì§‘ ëª¨ë“œ
                    with button_col:
                        if st.button("ì™„ë£Œ", key=f"done_button_{i}", use_container_width=True):
                            # í¸ì§‘ëœ ë‚´ìš©ì„ ì €ì¥í•˜ê³  í¸ì§‘ ëª¨ë“œ ì¢…ë£Œ
                            edited_content = st.session_state.get(f"temp_edit_{i}", "")
                            st.session_state[f"edited_chunk_{i}"] = edited_content
                            st.session_state[f"editing_chunk_{i}"] = False
                            # ì„ì‹œ í¸ì§‘ í‚¤ ì‚­ì œ
                            if f"temp_edit_{i}" in st.session_state:
                                del st.session_state[f"temp_edit_{i}"]
                            st.rerun()
                    
                    # í¸ì§‘ìš© ì„ì‹œ í‚¤ ì´ˆê¸°í™” (í¸ì§‘ ëª¨ë“œ ì‹œì‘ ì‹œì—ë§Œ)
                    if f"temp_edit_{i}" not in st.session_state:
                        st.session_state[f"temp_edit_{i}"] = st.session_state.get(f"edited_chunk_{i}", "")
                    
                    current_text = st.session_state.get(f"temp_edit_{i}", "")
                    height = len(current_text.splitlines()) * 25
                    st.text_area(
                        label="ë²ˆì—­ ìˆ˜ì •",
                        value=current_text,
                        key=f"temp_edit_{i}",
                        height=max(height, 100),
                        label_visibility="collapsed"
                    )
                else:
                    # ì½ê¸° ì „ìš© ëª¨ë“œ
                    with button_col:
                        if st.button("í¸ì§‘", key=f"edit_button_{i}", use_container_width=True):
                            st.session_state[f"editing_chunk_{i}"] = True
                            st.rerun()

                    with st.container(border=True):
                        translated_text = st.session_state.get(f"edited_chunk_{i}", "")
                        highlighted_target = highlight_terms(translated_text, target_terms)
                        st.markdown(highlighted_target, unsafe_allow_html=True)

        st.markdown("---")
        if st.button("ìˆ˜ì •ëœ ë‚´ìš© íŒŒì¼ì— ì €ì¥", type="primary"):
            final_chunks = []
            for i in range(len(source_chunks)):
                edited_content = st.session_state.get(f"edited_chunk_{i}", "")
                final_chunks.append(edited_content)
            
            final_content = "\n".join(final_chunks)
            
            output_dir = Path(output_path).parent
            output_dir.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(final_content)
            
            st.success(f"âœ… ìˆ˜ì •ëœ ë‚´ìš©ì´ ë‹¤ìŒ íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")

    except Exception as e:
        st.error(f"ê²°ê³¼ë¥¼ í‘œì‹œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}") 